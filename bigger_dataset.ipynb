{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjI9up_yRvFd"
   },
   "source": [
    "https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces?select=test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxOoFPZeuVGT",
    "outputId": "dd55612c-9222-4fc7-bc50-a51f0c117f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\xhlulu\\140k-real-and-fake-faces\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split,Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "import kagglehub\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import PyDataset\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"xhlulu/140k-real-and-fake-faces\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LddzaYu_kcX2",
    "outputId": "ba097bd0-0d7f-4146-ff97-aea9fd4f7724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "\n",
      "Class indices: {'fake': 0, 'real': 1}\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Data Configuration\n",
    "# ======================================\n",
    "IMG_SIZE = (224, 224)  # Can adjust to 256x256 if needed\n",
    "BATCH_SIZE = 32\n",
    "INPUT_SHAPE = (*IMG_SIZE, 3)\n",
    "\n",
    "# ======================================\n",
    "# Create Data Generators\n",
    "# ======================================\n",
    "# Define paths (MODIFY THESE PATHS IF NEEDED)\n",
    "TRAIN_DIR = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/train'\n",
    "VAL_DIR = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/valid'\n",
    "TEST_DIR = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/test'\n",
    "\n",
    "# Create base generators with normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True  # Explicitly shuffle training data\n",
    ")\n",
    "\n",
    "valid_generator = valid_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # No shuffle for validation\n",
    ")\n",
    "\n",
    "test_generator = valid_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # No shuffle for test\n",
    ")\n",
    "\n",
    "# Verify class indices\n",
    "print(\"\\nClass indices:\", train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w-H3QtNSBHHe"
   },
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Setup for GPU acceleration using your NVIDIA 4090 GPU\n",
    "# ======================================\n",
    "# This code enables CUDA acceleration on available GPUs.\n",
    "# It sets memory growth to avoid allocating all GPU memory at once.\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPUs are set for CUDA acceleration using your NVIDIA 4090 GPU.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# ======================================\n",
    "# Define the input shape for the models\n",
    "# ======================================\n",
    "# You can adjust INPUT_SHAPE based on your dataset dimensions.\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "# ======================================\n",
    "# Example Model 1: Original CNN\n",
    "# ======================================\n",
    "def build_cnn_model():\n",
    "    # Hyperparameters you can adjust:\n",
    "    # - Number of filters in Conv2D layers (e.g., 32, 64, 128)\n",
    "    # - Kernel size for convolution layers (e.g., (3,3))\n",
    "    # - Pooling size in MaxPooling2D layers (e.g., (2,2))\n",
    "    # - Dropout rate (e.g., 0.5)\n",
    "    # - Number of units in Dense layers (e.g., 512)\n",
    "    # - Learning rate for the optimizer (e.g., 0.0001)\n",
    "\n",
    "    model = Sequential([\n",
    "        # First convolutional block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE),  # 32 filters, 3x3 kernel\n",
    "        MaxPooling2D(2, 2),  # Pool size 2x2\n",
    "\n",
    "        # Second convolutional block\n",
    "        Conv2D(64, (3, 3), activation='relu'),  # 64 filters, 3x3 kernel\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        # Third convolutional block\n",
    "        Conv2D(128, (3, 3), activation='relu'),  # 128 filters, 3x3 kernel\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Flatten(),  # Flatten the output to feed into dense layers\n",
    "        Dropout(0.5),  # Dropout layer with rate 0.5 (adjustable to control overfitting)\n",
    "        Dense(512, activation='relu'),  # Dense layer with 512 units\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "\n",
    "    # Optimizer with adjustable learning rate\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # Adjust learning rate if necessary\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',  # Loss function for binary classification\n",
    "        metrics=['accuracy']  # Metric to monitor performance\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ======================================\n",
    "# Model 2: Pretrained ResNet50\n",
    "# ======================================\n",
    "def build_resnet_model():\n",
    "    # Hyperparameters you can adjust:\n",
    "    # - Choice of pretrained model and its configuration (e.g., ResNet50 with imagenet weights)\n",
    "    # - Whether to freeze the base model layers or fine-tune them (base_model.trainable)\n",
    "    # - Number of units in the dense layer after the base model (e.g., 256)\n",
    "    # - Dropout rate (e.g., 0.5)\n",
    "\n",
    "    # Load the pretrained ResNet50 model without the top layers\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=INPUT_SHAPE\n",
    "    )\n",
    "\n",
    "    # Freeze the base model layers to retain pretrained features.\n",
    "    # Change to \"base_model.trainable = True\" if you plan to fine-tune.\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),  # Flatten the output from the base model\n",
    "        Dense(256, activation='relu'),  # Dense layer with 256 units (adjustable)\n",
    "        Dropout(0.5),  # Dropout layer to reduce overfitting\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "\n",
    "    # Optimizer can be adjusted (e.g., setting a different learning rate)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "#========================\n",
    "#mobilenetv2\n",
    "#========================\n",
    "def build_mobilenetv2_model():\n",
    "    \"\"\"\n",
    "    Builds and returns a MobileNetV2-based model for binary classification.\n",
    "    This function replaces the ResNet50 model with minimal code changes.\n",
    "    Other parts of the training code remain the same.\n",
    "    \"\"\"\n",
    "    # Load the pretrained MobileNetV2 model with ImageNet weights\n",
    "    # 'include_top=False' removes the original classification head\n",
    "    # 'input_shape=INPUT_SHAPE' ensures it matches your data dimensions\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=INPUT_SHAPE\n",
    "    )\n",
    "\n",
    "    # Freeze all layers in the base model to retain the pretrained features\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build a new classification head on top of MobileNetV2\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),              # Flatten the feature maps\n",
    "        Dense(256, activation='relu'),  # Dense layer with 256 units\n",
    "        Dropout(0.5),          # Dropout for regularization\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model using the same hyperparameters as your ResNet code\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class MisclassifiedFakeLogger(Callback):\n",
    "    def __init__(self, valid_generator, valid_dir, max_images=10):\n",
    "        super().__init__()\n",
    "        self.valid_generator = valid_generator\n",
    "        self.valid_dir = valid_dir\n",
    "        self.max_images = max_images\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.valid_generator.reset()\n",
    "        preds = self.model.predict(\n",
    "            self.valid_generator, \n",
    "            steps=len(self.valid_generator), \n",
    "            verbose=0\n",
    "        ).flatten()\n",
    "\n",
    "        y_true = self.valid_generator.classes\n",
    "        filenames = self.valid_generator.filenames\n",
    "\n",
    "        # ✅ 真实标签是 fake (0)，但模型预测为 real (>= 0.5)\n",
    "        misclassified_indices = np.where((y_true == 1) & (preds <= 0.5))[0]\n",
    "\n",
    "        if len(misclassified_indices) == 0:\n",
    "            print(f\"[Epoch {epoch+1}] 没有错误识别的 fake 图片。\")\n",
    "            return\n",
    "\n",
    "        np.random.shuffle(misclassified_indices)\n",
    "        selected_indices = misclassified_indices[:self.max_images]\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] 展示 {len(selected_indices)} 张被误识别为 real 的 fake 图片：\")\n",
    "\n",
    "        for idx in selected_indices:\n",
    "            file_path = os.path.join(self.valid_dir, filenames[idx])\n",
    "            img = plt.imread(file_path)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"True: Fake(0), Pred: {preds[idx]:.4f} → Real(1)\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "misclassified_logger = MisclassifiedFakeLogger(\n",
    "    valid_generator=valid_generator, \n",
    "    valid_dir=VAL_DIR, \n",
    "    max_images=10  # 每个 epoch 最多显示10张\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "rFjw30xRvQhE",
    "outputId": "dc76d921-80f5-4118-fd6b-067f26a45a03",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 237ms/step - accuracy: 0.6839 - loss: 0.5824 - val_accuracy: 0.8259 - val_loss: 0.3942\n",
      "Epoch 2/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 224ms/step - accuracy: 0.8391 - loss: 0.3678 - val_accuracy: 0.8716 - val_loss: 0.3004\n",
      "Epoch 3/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 224ms/step - accuracy: 0.8870 - loss: 0.2742 - val_accuracy: 0.9121 - val_loss: 0.2187\n",
      "Epoch 4/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 231ms/step - accuracy: 0.9172 - loss: 0.2068 - val_accuracy: 0.9376 - val_loss: 0.1739\n",
      "Epoch 5/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 230ms/step - accuracy: 0.9366 - loss: 0.1617 - val_accuracy: 0.9491 - val_loss: 0.1361\n",
      "Epoch 6/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m848s\u001b[0m 271ms/step - accuracy: 0.9533 - loss: 0.1238 - val_accuracy: 0.9582 - val_loss: 0.1151\n",
      "Epoch 7/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1226s\u001b[0m 392ms/step - accuracy: 0.9652 - loss: 0.0943 - val_accuracy: 0.9646 - val_loss: 0.0983\n",
      "Epoch 8/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 286ms/step - accuracy: 0.9732 - loss: 0.0713 - val_accuracy: 0.9631 - val_loss: 0.1002\n",
      "Epoch 9/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 225ms/step - accuracy: 0.9804 - loss: 0.0550 - val_accuracy: 0.9741 - val_loss: 0.0732\n",
      "Epoch 10/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 226ms/step - accuracy: 0.9843 - loss: 0.0452 - val_accuracy: 0.9742 - val_loss: 0.0724\n",
      "Epoch 11/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 226ms/step - accuracy: 0.9882 - loss: 0.0334 - val_accuracy: 0.9740 - val_loss: 0.0766\n",
      "Epoch 12/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 225ms/step - accuracy: 0.9900 - loss: 0.0291 - val_accuracy: 0.9743 - val_loss: 0.0717\n",
      "Epoch 13/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 226ms/step - accuracy: 0.9913 - loss: 0.0253 - val_accuracy: 0.9780 - val_loss: 0.0660\n",
      "Epoch 14/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 226ms/step - accuracy: 0.9929 - loss: 0.0216 - val_accuracy: 0.9798 - val_loss: 0.0601\n",
      "Epoch 15/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 226ms/step - accuracy: 0.9937 - loss: 0.0184 - val_accuracy: 0.9760 - val_loss: 0.0740\n",
      "Epoch 16/20\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 231ms/step - accuracy: 0.9940 - loss: 0.0166 - val_accuracy: 0.9772 - val_loss: 0.0730\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# ======================================\n",
    "# test record\n",
    "# ======================================\n",
    "class ExperimentLogger(Callback):\n",
    "    def __init__(self, test_generator, csv_path='training_logs.csv'):\n",
    "        super().__init__()\n",
    "        self.test_generator = test_generator\n",
    "        self.csv_path = csv_path\n",
    "        self.results = []\n",
    "        \n",
    "        self.test_steps = test_generator.samples // test_generator.batch_size\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # initialize \n",
    "        with open(self.csv_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                'epoch', 'train_loss', 'train_acc',\n",
    "                'val_loss', 'val_acc', 'test_loss', 'test_acc'\n",
    "            ])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # reset test_geberator\n",
    "        self.test_generator.reset()\n",
    "        \n",
    "        test_loss, test_acc = self.model.evaluate(\n",
    "            self.test_generator,\n",
    "            steps=self.test_steps,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # collect data\n",
    "        log_data = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': logs.get('loss'),\n",
    "            'train_acc': logs.get('accuracy'),\n",
    "            'val_loss': logs.get('val_loss'),\n",
    "            'val_acc': logs.get('val_accuracy'),\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc\n",
    "        }\n",
    "        self.results.append(log_data)\n",
    "        \n",
    "        # write in CSV（four digits）\n",
    "        with open(self.csv_path, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                log_data['epoch'],\n",
    "                round(log_data['train_loss'], 4),\n",
    "                round(log_data['train_acc'], 4),\n",
    "                round(log_data['val_loss'], 4),\n",
    "                round(log_data['val_acc'], 4),\n",
    "                round(log_data['test_loss'], 4),\n",
    "                round(log_data['test_acc'], 4)\n",
    "            ])\n",
    "# ======================================\n",
    "# add logger for training\n",
    "# ======================================\n",
    "# initialize model\n",
    "model = build_cnn_model()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# create logger\n",
    "experiment_logger = ExperimentLogger(test_generator, csv_path='resnet_experiment_logs.csv')\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, experiment_logger]  # add logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在将模型保存到 ./my_model_trained_on_A.keras...\n",
      "模型已保存。\n"
     ]
    }
   ],
   "source": [
    "# 定义保存路径和文件名 (添加 .keras 扩展名)\n",
    "saved_model_path = './my_model_trained_on_A.keras' \n",
    "\n",
    "# 保存模型\n",
    "print(f\"正在将模型保存到 {saved_model_path}...\")\n",
    "model.save(saved_model_path)\n",
    "print(\"模型已保存。\")\n",
    "\n",
    "# 加载时也使用相同的路径\n",
    "loaded_model = tf.keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在将模型保存到 ./my_model_trained_on_A.h5...\n",
      "模型已保存。\n"
     ]
    }
   ],
   "source": [
    "# 定义保存路径和文件名 (添加 .h5 扩展名)\n",
    "saved_model_path = './my_model_trained_on_A.h5'\n",
    "\n",
    "# 保存模型\n",
    "print(f\"正在将模型保存到 {saved_model_path}...\")\n",
    "model.save(saved_model_path)\n",
    "print(\"模型已保存。\")\n",
    "\n",
    "# 加载时也使用相同的路径\n",
    "# loaded_model = tf.keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在将模型导出到 SavedModel 目录 ./my_model_trained_on_A_savedmodel...\n",
      "INFO:tensorflow:Assets written to: ./my_model_trained_on_A_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_model_trained_on_A_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at './my_model_trained_on_A_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_11')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2016903195408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903197136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903196560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903197904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903197328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903198672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903198096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903199440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903198864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2016903200208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "模型已导出。\n"
     ]
    }
   ],
   "source": [
    "# 定义要保存到的目录路径 (不需要扩展名)\n",
    "saved_model_directory = './my_model_trained_on_A_savedmodel' \n",
    "\n",
    "# 导出模型为 SavedModel 格式\n",
    "print(f\"正在将模型导出到 SavedModel 目录 {saved_model_directory}...\")\n",
    "model.export(saved_model_directory)\n",
    "print(\"模型已导出。\")\n",
    "\n",
    "# 加载时使用目录路径\n",
    "# loaded_model = tf.keras.models.load_model(saved_model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1XTcp7qMvaTO"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'standard_30epoch_experiment_logs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     plt.show()\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 生成图表\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mplot_training_curves\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstandard_30epoch_experiment_logs.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mplot_training_curves\u001b[39m\u001b[34m(csv_path, figsize)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_training_curves\u001b[39m(csv_path, figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m)):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Read CSV data\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Create plots\u001b[39;00m\n\u001b[32m     10\u001b[39m     plt.figure(figsize=figsize)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'standard_30epoch_experiment_logs.csv'"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Visualization Function\n",
    "# ======================================\n",
    "def plot_training_curves(csv_path, figsize=(12, 6)):\n",
    "    # Read CSV data\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Create plots\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Loss curves\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df['epoch'], df['train_loss'], label='Train Loss')\n",
    "    plt.plot(df['epoch'], df['val_loss'], label='Val Loss')\n",
    "    plt.plot(df['epoch'], df['test_loss'], label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy curves\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df['epoch'], df['train_acc'], label='Train Acc')\n",
    "    plt.plot(df['epoch'], df['val_acc'], label='Val Acc')\n",
    "    plt.plot(df['epoch'], df['test_acc'], label='Test Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('standard_30epoch_experiment_logs.png') \n",
    "    plt.show()\n",
    "\n",
    "# 生成图表\n",
    "plot_training_curves('standard_30epoch_experiment_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./my_model_trained_on_A.keras...\n",
      "Model loaded successfully.\n",
      "Downloading/Locating 'hardfakevsrealfaces' dataset...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Dataset path: C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\n",
      "Loading new dataset from C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1...\n",
      "Found 1289 images belonging to 2 classes.\n",
      "New dataset loaded successfully.\n",
      "Class indices: {'fake': 0, 'real': 1}\n",
      "Evaluating model on the new dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.4288 - loss: 2.7033\n",
      "\n",
      "Evaluation on the new dataset:\n",
      "loss: 1.6982\n",
      "compile_metrics: 0.6330\n",
      "\n",
      "Making predictions on the new dataset (this may take a while)...\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step\n",
      "Predictions and true classes obtained.\n",
      "\n",
      "Accuracy Score: 0.6330488750969744\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.33      0.49       700\n",
      "        real       0.55      1.00      0.71       589\n",
      "\n",
      "    accuracy                           0.63      1289\n",
      "   macro avg       0.78      0.66      0.60      1289\n",
      "weighted avg       0.79      0.63      0.59      1289\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[228 472]\n",
      " [  1 588]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing script finished.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import kagglehub # Make sure kagglehub is imported\n",
    "\n",
    "# Define the path to your saved model\n",
    "saved_model_path = './my_model_trained_on_A.keras'\n",
    "\n",
    "# Load the saved model\n",
    "print(f\"Loading model from {saved_model_path}...\")\n",
    "try:\n",
    "    loaded_model = tf.keras.models.load_model(saved_model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    # Exit if the model cannot be loaded\n",
    "    exit()\n",
    "\n",
    "# --- START CORRECTION ---\n",
    "# Define and download the path to the new dataset\n",
    "print(\"Downloading/Locating 'hardfakevsrealfaces' dataset...\")\n",
    "try:\n",
    "    # This line will define the 'path' variable\n",
    "    path_to_new_dataset = kagglehub.dataset_download(\"hamzaboulahia/hardfakevsrealfaces\")\n",
    "    print(f\"Dataset path: {path_to_new_dataset}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading dataset with kagglehub: {e}\")\n",
    "    exit()\n",
    "\n",
    "NEW_DATASET_PATH = path_to_new_dataset # Use the newly defined path\n",
    "# --- END CORRECTION ---\n",
    "\n",
    "# Verify that the dataset path exists\n",
    "if not os.path.exists(NEW_DATASET_PATH):\n",
    "    print(f\"Error: The dataset path {NEW_DATASET_PATH} does not exist or was not correctly returned by kagglehub.\")\n",
    "    exit()\n",
    "\n",
    "# Image dimensions and batch size (should ideally match what the model was trained on)\n",
    "IMG_SIZE = (loaded_model.input_shape[1], loaded_model.input_shape[2]) # Get input size from the loaded model\n",
    "BATCH_SIZE = 32 # You can adjust this\n",
    "\n",
    "# Create an ImageDataGenerator for the new dataset\n",
    "# We only need rescaling, similar to how validation/test data is usually processed.\n",
    "new_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the new dataset\n",
    "print(f\"Loading new dataset from {NEW_DATASET_PATH}...\")\n",
    "try:\n",
    "    new_generator = new_datagen.flow_from_directory(\n",
    "        NEW_DATASET_PATH,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary', # Assuming 'fake' and 'real' correspond to 0 and 1\n",
    "        shuffle=False # Important for evaluation to keep track of predictions\n",
    "    )\n",
    "    print(\"New dataset loaded successfully.\")\n",
    "    print(\"Class indices:\", new_generator.class_indices)\n",
    "except Exception as e:\n",
    "    print(f\"Error creating data generator for the new dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ... (the rest of your evaluation code remains the same) ...\n",
    "\n",
    "# Check if the generator found any images\n",
    "if new_generator.samples == 0:\n",
    "    print(f\"No images found in {NEW_DATASET_PATH}. Please check the directory structure.\")\n",
    "    print(\"Expected subdirectories 'fake' and 'real' with images inside.\")\n",
    "    exit()\n",
    "\n",
    "# Evaluate the model on the new dataset\n",
    "print(\"Evaluating model on the new dataset...\")\n",
    "try:\n",
    "    evaluation_results = loaded_model.evaluate(new_generator, verbose=1)\n",
    "    print(\"\\nEvaluation on the new dataset:\")\n",
    "    for metric_name, metric_value in zip(loaded_model.metrics_names, evaluation_results):\n",
    "        print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model evaluation: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Optional: Get predictions and true labels to calculate more metrics or show a confusion matrix\n",
    "print(\"\\nMaking predictions on the new dataset (this may take a while)...\")\n",
    "try:\n",
    "    predictions = loaded_model.predict(new_generator, verbose=1)\n",
    "    predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "    true_classes = new_generator.classes\n",
    "    filenames = new_generator.filenames\n",
    "\n",
    "    print(\"Predictions and true classes obtained.\")\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "    print(\"\\nAccuracy Score:\", accuracy_score(true_classes, predicted_classes))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    target_names = [k for k, v in sorted(new_generator.class_indices.items(), key=lambda item: item[1])]\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=target_names))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    print(cm)\n",
    "\n",
    "    import seaborn as sns # Ensure seaborn is imported if you use it\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix on New Dataset')\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction or detailed metrics calculation: {e}\")\n",
    "\n",
    "print(\"\\nTesting script finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locating/Downloading Dataset B ('hardfakevsrealfaces')...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Dataset B path: C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\n",
      "Preparing combined training data in ./combined_train_data...\n",
      "Removing existing combined directory: ./combined_train_data\n",
      "Copying Dataset A training images...\n",
      "Copied 50000 images from C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/train\\fake to ./combined_train_data\\fake\n",
      "Copied 50000 images from C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/train\\real to ./combined_train_data\\real\n",
      "Copying Dataset B images...\n",
      "Copied 700 images from C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\\fake to ./combined_train_data\\fake\n",
      "Copied 589 images from C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\\real to ./combined_train_data\\real\n",
      "Finished preparing combined training data.\n",
      "Creating data generators...\n",
      "Found 101289 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 1289 images belonging to 2 classes.\n",
      "Class indices (Combined Train): {'fake': 0, 'real': 1}\n",
      "Class indices (Dataset A Val): {'fake': 0, 'real': 1}\n",
      "Class indices (Dataset B Eval): {'fake': 0, 'real': 1}\n",
      "Loading pre-trained model from ./my_model_trained_on_A.keras...\n",
      "Model loaded successfully.\n",
      "Model re-compiled with learning rate: 1e-05\n",
      "Starting fine-tuning...\n",
      "Epoch 1/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1427s\u001b[0m 450ms/step - accuracy: 0.9930 - loss: 0.0268 - val_accuracy: 0.9788 - val_loss: 0.0618\n",
      "Epoch 2/10\n",
      "\u001b[1m   1/3165\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:53\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9787 - val_loss: 0.0618\n",
      "Epoch 3/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 234ms/step - accuracy: 0.9947 - loss: 0.0197 - val_accuracy: 0.9790 - val_loss: 0.0609\n",
      "Epoch 4/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9790 - val_loss: 0.0610\n",
      "Epoch 5/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m692s\u001b[0m 219ms/step - accuracy: 0.9954 - loss: 0.0162 - val_accuracy: 0.9803 - val_loss: 0.0598\n",
      "Epoch 6/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9804 - val_loss: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 218ms/step - accuracy: 0.9960 - loss: 0.0141 - val_accuracy: 0.9809 - val_loss: 0.0579\n",
      "Epoch 8/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.9808 - val_loss: 0.0578\n",
      "Epoch 9/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 217ms/step - accuracy: 0.9966 - loss: 0.0130 - val_accuracy: 0.9807 - val_loss: 0.0575\n",
      "Epoch 10/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9805 - val_loss: 0.0574\n",
      "Fine-tuning finished.\n",
      "\n",
      "Evaluating fine-tuned model on Dataset A (Test Set)...\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.9776 - loss: 0.0682\n",
      "Dataset A - Test Loss: 0.0624, Test Accuracy: 0.9789\n",
      "\n",
      "Evaluating fine-tuned model on Dataset B...\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8433 - loss: 0.4752\n",
      "Dataset B - Loss: 0.2711, Accuracy: 0.9061\n",
      "\n",
      "Generating detailed report for Dataset B...\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\n",
      "\n",
      "Dataset B - Accuracy Score: 0.9061287820015516\n",
      "\n",
      "Dataset B - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.83      0.91       700\n",
      "        real       0.83      1.00      0.91       589\n",
      "\n",
      "    accuracy                           0.91      1289\n",
      "   macro avg       0.91      0.91      0.91      1289\n",
      "weighted avg       0.92      0.91      0.91      1289\n",
      "\n",
      "\n",
      "Dataset B - Confusion Matrix:\n",
      "[[579 121]\n",
      " [  0 589]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the fine-tuned model to ./my_model_finetuned.keras...\n",
      "Fine-tuned model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam # Import Adam optimizer\n",
    "import os\n",
    "import shutil # Library for file operations (like copying)\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# Configuration for Fine-Tuning\n",
    "# =====================================\n",
    "# Paths\n",
    "PRETRAINED_MODEL_PATH = './my_model_trained_on_A.keras'\n",
    "FINETUNED_MODEL_PATH = './my_model_finetuned.keras' # Path to save the fine-tuned model\n",
    "\n",
    "# Original Dataset A paths (Assuming these variables are still defined from your previous cells)\n",
    "# If not, redefine them here:\n",
    "TRAIN_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/train'\n",
    "VAL_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/valid'\n",
    "TEST_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/test'\n",
    "\n",
    "# New Dataset B path (Download if not already present, get the path)\n",
    "print(\"Locating/Downloading Dataset B ('hardfakevsrealfaces')...\")\n",
    "try:\n",
    "    DATASET_B_PATH = kagglehub.dataset_download(\"hamzaboulahia/hardfakevsrealfaces\")\n",
    "    print(f\"Dataset B path: {DATASET_B_PATH}\")\n",
    "    # Check if the dataset path contains 'fake' and 'real' subdirectories needed for flow_from_directory\n",
    "    if not (os.path.exists(os.path.join(DATASET_B_PATH, 'fake')) and os.path.exists(os.path.join(DATASET_B_PATH, 'real'))):\n",
    "         # If not, assume the structure might be nested, e.g., inside another folder. Adjust DATASET_B_PATH if needed.\n",
    "         # Example adjustment (uncomment and modify if necessary):\n",
    "         # potential_nested_path = os.path.join(DATASET_B_PATH, 'hardfakevsrealfaces') # Or whatever the actual subfolder name is\n",
    "         # if os.path.exists(potential_nested_path) and os.path.exists(os.path.join(potential_nested_path, 'fake')):\n",
    "         #    DATASET_B_PATH = potential_nested_path\n",
    "         #    print(f\"Adjusted Dataset B path to: {DATASET_B_PATH}\")\n",
    "         # else:\n",
    "             print(f\"Warning: Could not find 'fake'/'real' subdirs directly in {DATASET_B_PATH}. ImageDataGenerator might fail.\")\n",
    "             # Consider adding manual inspection or error handling here if the structure is unknown.\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading/locating dataset B with kagglehub: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Path for combined training data\n",
    "COMBINED_TRAIN_DIR = './combined_train_data'\n",
    "\n",
    "# Fine-tuning Hyperparameters (These are crucial!)\n",
    "LEARNING_RATE = 1e-5  # Start with a low learning rate for fine-tuning\n",
    "EPOCHS = 10           # Maximum number of epochs for fine-tuning (EarlyStopping will likely stop it sooner)\n",
    "BATCH_SIZE = 32       # Usually kept the same as initial training\n",
    "IMG_SIZE = (224, 224) # Should match the input size of your loaded model\n",
    "\n",
    "# =====================================\n",
    "# 1. Prepare Combined Training Data\n",
    "# =====================================\n",
    "print(f\"Preparing combined training data in {COMBINED_TRAIN_DIR}...\")\n",
    "\n",
    "# Remove the combined directory if it exists to start fresh\n",
    "if os.path.exists(COMBINED_TRAIN_DIR):\n",
    "    print(f\"Removing existing combined directory: {COMBINED_TRAIN_DIR}\")\n",
    "    shutil.rmtree(COMBINED_TRAIN_DIR)\n",
    "\n",
    "# Create the directory structure: combined_train_data/fake and combined_train_data/real\n",
    "os.makedirs(os.path.join(COMBINED_TRAIN_DIR, 'fake'), exist_ok=True)\n",
    "os.makedirs(os.path.join(COMBINED_TRAIN_DIR, 'real'), exist_ok=True)\n",
    "\n",
    "# Function to copy images\n",
    "def copy_images(src_dir, dest_dir, class_name):\n",
    "    \"\"\"Copies images from src_dir/class_name to dest_dir/class_name.\"\"\"\n",
    "    src_class_dir = os.path.join(src_dir, class_name)\n",
    "    dest_class_dir = os.path.join(dest_dir, class_name)\n",
    "    if not os.path.exists(src_class_dir):\n",
    "        print(f\"Warning: Source directory not found {src_class_dir}\")\n",
    "        return 0\n",
    "    count = 0\n",
    "    for filename in os.listdir(src_class_dir):\n",
    "        src_file = os.path.join(src_class_dir, filename)\n",
    "        dest_file = os.path.join(dest_class_dir, filename)\n",
    "        if os.path.isfile(src_file):\n",
    "            try:\n",
    "                # Add a prefix to avoid name collisions between datasets (optional but safer)\n",
    "                new_filename = f\"{class_name}_dataset_{os.path.basename(src_dir)}_{filename}\"\n",
    "                dest_file_prefixed = os.path.join(dest_class_dir, new_filename)\n",
    "                shutil.copy2(src_file, dest_file_prefixed) # copy2 preserves metadata\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file} to {dest_file_prefixed}: {e}\")\n",
    "    print(f\"Copied {count} images from {src_class_dir} to {dest_class_dir}\")\n",
    "    return count\n",
    "\n",
    "# Copy training images from Dataset A\n",
    "print(\"Copying Dataset A training images...\")\n",
    "copy_images(TRAIN_DIR_A, COMBINED_TRAIN_DIR, 'fake')\n",
    "copy_images(TRAIN_DIR_A, COMBINED_TRAIN_DIR, 'real')\n",
    "\n",
    "# Copy images from Dataset B (assuming it has 'fake' and 'real' subdirs)\n",
    "print(\"Copying Dataset B images...\")\n",
    "copy_images(DATASET_B_PATH, COMBINED_TRAIN_DIR, 'fake')\n",
    "copy_images(DATASET_B_PATH, COMBINED_TRAIN_DIR, 'real')\n",
    "\n",
    "print(\"Finished preparing combined training data.\")\n",
    "\n",
    "# =====================================\n",
    "# 2. Create Data Generators\n",
    "# =====================================\n",
    "# Generator for combined training data (with augmentation if desired)\n",
    "train_datagen_combined = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Add augmentations if you used them in the original training, e.g.:\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.2,\n",
    "    # height_shift_range=0.2,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=0.2,\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generator for Dataset A validation data (only rescaling)\n",
    "valid_test_datagen_A = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generator for Dataset B data (only rescaling) - for evaluation\n",
    "datagen_B = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Create the generator flows\n",
    "print(\"Creating data generators...\")\n",
    "train_generator_combined = train_datagen_combined.flow_from_directory(\n",
    "    COMBINED_TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Use the original validation generator for Dataset A\n",
    "valid_generator_A = valid_test_datagen_A.flow_from_directory(\n",
    "    VAL_DIR_A,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Use the original test generator for Dataset A\n",
    "test_generator_A = valid_test_datagen_A.flow_from_directory(\n",
    "    TEST_DIR_A,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create a generator for evaluating on all of Dataset B\n",
    "# We reuse the DATASET_B_PATH, assuming it directly contains 'fake'/'real' folders\n",
    "generator_B = datagen_B.flow_from_directory(\n",
    "    DATASET_B_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Verify class indices are consistent (should be {'fake': 0, 'real': 1})\n",
    "print(\"Class indices (Combined Train):\", train_generator_combined.class_indices)\n",
    "print(\"Class indices (Dataset A Val):\", valid_generator_A.class_indices)\n",
    "print(\"Class indices (Dataset B Eval):\", generator_B.class_indices)\n",
    "# If indices are different or swapped, this indicates a problem in data setup!\n",
    "\n",
    "# =====================================\n",
    "# 3. Load Pre-trained Model and Re-compile\n",
    "# =====================================\n",
    "print(f\"Loading pre-trained model from {PRETRAINED_MODEL_PATH}...\")\n",
    "try:\n",
    "    model = tf.keras.models.load_model(PRETRAINED_MODEL_PATH)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    # Optional: Print model summary to verify\n",
    "    # model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Re-compile the model with a low learning rate for fine-tuning\n",
    "# It's important to use a *new* optimizer instance\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE), # Use Adam optimizer with the specified low learning rate\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(f\"Model re-compiled with learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# =====================================\n",
    "# 4. Fine-tune the Model\n",
    "# =====================================\n",
    "# Setup EarlyStopping for fine-tuning\n",
    "early_stop_finetune = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor validation loss on Dataset A's validation set\n",
    "    patience=3,               # Stop if no improvement after 3 epochs (can adjust)\n",
    "    restore_best_weights=True # Restore weights from the epoch with the best validation loss\n",
    ")\n",
    "\n",
    "print(\"Starting fine-tuning...\")\n",
    "history_finetune = model.fit(\n",
    "    train_generator_combined,\n",
    "    steps_per_epoch=max(1, train_generator_combined.samples // BATCH_SIZE), # Ensure at least 1 step\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_generator_A,\n",
    "    validation_steps=max(1, valid_generator_A.samples // BATCH_SIZE), # Ensure at least 1 step\n",
    "    callbacks=[early_stop_finetune]\n",
    ")\n",
    "print(\"Fine-tuning finished.\")\n",
    "\n",
    "# =====================================\n",
    "# 5. Evaluate the Fine-tuned Model\n",
    "# =====================================\n",
    "print(\"\\nEvaluating fine-tuned model on Dataset A (Test Set)...\")\n",
    "eval_A = model.evaluate(test_generator_A)\n",
    "print(f\"Dataset A - Test Loss: {eval_A[0]:.4f}, Test Accuracy: {eval_A[1]:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating fine-tuned model on Dataset B...\")\n",
    "eval_B = model.evaluate(generator_B)\n",
    "print(f\"Dataset B - Loss: {eval_B[0]:.4f}, Accuracy: {eval_B[1]:.4f}\")\n",
    "\n",
    "# Detailed report for Dataset B\n",
    "print(\"\\nGenerating detailed report for Dataset B...\")\n",
    "try:\n",
    "    predictions_B = model.predict(generator_B)\n",
    "    predicted_classes_B = (predictions_B > 0.5).astype(int).flatten()\n",
    "    true_classes_B = generator_B.classes\n",
    "    target_names_B = [k for k, v in sorted(generator_B.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "    print(\"\\nDataset B - Accuracy Score:\", accuracy_score(true_classes_B, predicted_classes_B))\n",
    "    print(\"\\nDataset B - Classification Report:\")\n",
    "    print(classification_report(true_classes_B, predicted_classes_B, target_names=target_names_B))\n",
    "\n",
    "    print(\"\\nDataset B - Confusion Matrix:\")\n",
    "    cm_B = confusion_matrix(true_classes_B, predicted_classes_B)\n",
    "    print(cm_B)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_B, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_B, yticklabels=target_names_B)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix on Dataset B (Fine-tuned Model)')\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during detailed evaluation on Dataset B: {e}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 6. Save the Fine-tuned Model\n",
    "# =====================================\n",
    "print(f\"\\nSaving the fine-tuned model to {FINETUNED_MODEL_PATH}...\")\n",
    "try:\n",
    "    model.save(FINETUNED_MODEL_PATH)\n",
    "    print(\"Fine-tuned model saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving fine-tuned model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locating/Downloading Dataset B ('hardfakevsrealfaces')...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Dataset B path: C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\n",
      "Preparing combined training data in ./combined_train_data...\n",
      "Copying Dataset A training images...\n",
      "Copied 50000 images from C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/train\\fake to ./combined_train_data\\fake\n",
      "Copied 50000 images from C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/train\\real to ./combined_train_data\\real\n",
      "Copying Dataset B images...\n",
      "Copied 700 images from C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\\fake to ./combined_train_data\\fake\n",
      "Copied 589 images from C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\\real to ./combined_train_data\\real\n",
      "Finished preparing combined training data.\n",
      "Creating data generators...\n",
      "Found 101289 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 1289 images belonging to 2 classes.\n",
      "Class indices (Combined Train): {'fake': 0, 'real': 1}\n",
      "Class indices (Dataset A Val): {'fake': 0, 'real': 1}\n",
      "Class indices (Dataset B Eval): {'fake': 0, 'real': 1}\n",
      "Loading pre-trained model from ./my_model_trained_on_A.keras...\n",
      "Model loaded successfully.\n",
      "Model re-compiled with learning rate: 1e-05\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1293s\u001b[0m 408ms/step - accuracy: 0.7898 - loss: 0.6181 - val_accuracy: 0.9022 - val_loss: 0.2345\n",
      "Epoch 2/10\n",
      "\u001b[1m   1/3165\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:08\u001b[0m 211ms/step - accuracy: 0.9062 - loss: 0.2895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2895 - val_accuracy: 0.9018 - val_loss: 0.2354\n",
      "Epoch 3/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 275ms/step - accuracy: 0.8597 - loss: 0.3237 - val_accuracy: 0.9219 - val_loss: 0.1924\n",
      "Epoch 4/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.2163 - val_accuracy: 0.9219 - val_loss: 0.1924\n",
      "Epoch 5/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m873s\u001b[0m 276ms/step - accuracy: 0.8824 - loss: 0.2771 - val_accuracy: 0.9367 - val_loss: 0.1623\n",
      "Epoch 6/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.2118 - val_accuracy: 0.9380 - val_loss: 0.1600\n",
      "Epoch 7/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m876s\u001b[0m 277ms/step - accuracy: 0.8965 - loss: 0.2489 - val_accuracy: 0.9333 - val_loss: 0.1696\n",
      "Epoch 8/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2092 - val_accuracy: 0.9319 - val_loss: 0.1721\n",
      "Epoch 9/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 275ms/step - accuracy: 0.9073 - loss: 0.2273 - val_accuracy: 0.9424 - val_loss: 0.1518\n",
      "Epoch 10/10\n",
      "\u001b[1m3165/3165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.8750 - loss: 0.3370 - val_accuracy: 0.9441 - val_loss: 0.1492\n",
      "Fine-tuning finished.\n",
      "\n",
      "Evaluating fine-tuned model on Dataset A (Test Set)...\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.9760 - loss: 0.0724\n",
      "Dataset A - Test Loss: 0.1471, Test Accuracy: 0.9435\n",
      "\n",
      "Evaluating fine-tuned model on Dataset B...\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8186 - loss: 0.4171\n",
      "Dataset B - Loss: 0.2638, Accuracy: 0.8844\n",
      "\n",
      "Generating detailed report for Dataset B...\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step\n",
      "\n",
      "Dataset B - Accuracy Score: 0.8844065166795966\n",
      "\n",
      "Dataset B - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.79      0.88       700\n",
      "        real       0.80      1.00      0.89       589\n",
      "\n",
      "    accuracy                           0.88      1289\n",
      "   macro avg       0.90      0.89      0.88      1289\n",
      "weighted avg       0.91      0.88      0.88      1289\n",
      "\n",
      "\n",
      "Dataset B - Confusion Matrix:\n",
      "[[552 148]\n",
      " [  1 588]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the fine-tuned model to ./my_model_finetuned_v3.keras...\n",
      "Fine-tuned model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam # Import Adam optimizer\n",
    "import os\n",
    "import shutil # Library for file operations (like copying)\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# Configuration for Fine-Tuning\n",
    "# =====================================\n",
    "# Paths\n",
    "\n",
    "# Define the base model and path to new model, this one has hyperparameters on\n",
    "PRETRAINED_MODEL_PATH = './my_model_trained_on_A.keras'\n",
    "FINETUNED_MODEL_PATH = './my_model_finetuned_v3.keras' \n",
    "\n",
    "# Original Dataset A paths (Assuming these variables are still defined from your previous cells)\n",
    "# If not, redefine them here:\n",
    "TRAIN_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/train'\n",
    "VAL_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/valid'\n",
    "TEST_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/test'\n",
    "\n",
    "# New Dataset B path (Download if not already present, get the path)\n",
    "print(\"Locating/Downloading Dataset B ('hardfakevsrealfaces')...\")\n",
    "try:\n",
    "    DATASET_B_PATH = kagglehub.dataset_download(\"hamzaboulahia/hardfakevsrealfaces\")\n",
    "    print(f\"Dataset B path: {DATASET_B_PATH}\")\n",
    "    # Check if the dataset path contains 'fake' and 'real' subdirectories needed for flow_from_directory\n",
    "    if not (os.path.exists(os.path.join(DATASET_B_PATH, 'fake')) and os.path.exists(os.path.join(DATASET_B_PATH, 'real'))):\n",
    "         # If not, assume the structure might be nested, e.g., inside another folder. Adjust DATASET_B_PATH if needed.\n",
    "         # Example adjustment (uncomment and modify if necessary):\n",
    "         # potential_nested_path = os.path.join(DATASET_B_PATH, 'hardfakevsrealfaces') # Or whatever the actual subfolder name is\n",
    "         # if os.path.exists(potential_nested_path) and os.path.exists(os.path.join(potential_nested_path, 'fake')):\n",
    "         #    DATASET_B_PATH = potential_nested_path\n",
    "         #    print(f\"Adjusted Dataset B path to: {DATASET_B_PATH}\")\n",
    "         # else:\n",
    "             print(f\"Warning: Could not find 'fake'/'real' subdirs directly in {DATASET_B_PATH}. ImageDataGenerator might fail.\")\n",
    "             # Consider adding manual inspection or error handling here if the structure is unknown.\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading/locating dataset B with kagglehub: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Path for combined training data\n",
    "COMBINED_TRAIN_DIR = './combined_train_data'\n",
    "\n",
    "# Fine-tuning Hyperparameters (These are crucial!)\n",
    "LEARNING_RATE = 1e-5  # Start with a low learning rate for fine-tuning\n",
    "EPOCHS = 10           # Maximum number of epochs for fine-tuning (EarlyStopping will likely stop it sooner)\n",
    "BATCH_SIZE = 32       # Usually kept the same as initial training\n",
    "IMG_SIZE = (224, 224) # Should match the input size of your loaded model\n",
    "\n",
    "# =====================================\n",
    "# 1. Prepare Combined Training Data\n",
    "# =====================================\n",
    "print(f\"Preparing combined training data in {COMBINED_TRAIN_DIR}...\")\n",
    "\n",
    "# Remove the combined directory if it exists to start fresh\n",
    "if os.path.exists(COMBINED_TRAIN_DIR):\n",
    "    print(f\"Removing existing combined directory: {COMBINED_TRAIN_DIR}\")\n",
    "    shutil.rmtree(COMBINED_TRAIN_DIR)\n",
    "\n",
    "# Create the directory structure: combined_train_data/fake and combined_train_data/real\n",
    "os.makedirs(os.path.join(COMBINED_TRAIN_DIR, 'fake'), exist_ok=True)\n",
    "os.makedirs(os.path.join(COMBINED_TRAIN_DIR, 'real'), exist_ok=True)\n",
    "\n",
    "# Function to copy images\n",
    "def copy_images(src_dir, dest_dir, class_name):\n",
    "    \"\"\"Copies images from src_dir/class_name to dest_dir/class_name.\"\"\"\n",
    "    src_class_dir = os.path.join(src_dir, class_name)\n",
    "    dest_class_dir = os.path.join(dest_dir, class_name)\n",
    "    if not os.path.exists(src_class_dir):\n",
    "        print(f\"Warning: Source directory not found {src_class_dir}\")\n",
    "        return 0\n",
    "    count = 0\n",
    "    for filename in os.listdir(src_class_dir):\n",
    "        src_file = os.path.join(src_class_dir, filename)\n",
    "        dest_file = os.path.join(dest_class_dir, filename)\n",
    "        if os.path.isfile(src_file):\n",
    "            try:\n",
    "                # Add a prefix to avoid name collisions between datasets (optional but safer)\n",
    "                new_filename = f\"{class_name}_dataset_{os.path.basename(src_dir)}_{filename}\"\n",
    "                dest_file_prefixed = os.path.join(dest_class_dir, new_filename)\n",
    "                shutil.copy2(src_file, dest_file_prefixed) # copy2 preserves metadata\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file} to {dest_file_prefixed}: {e}\")\n",
    "    print(f\"Copied {count} images from {src_class_dir} to {dest_class_dir}\")\n",
    "    return count\n",
    "\n",
    "# Copy training images from Dataset A\n",
    "print(\"Copying Dataset A training images...\")\n",
    "copy_images(TRAIN_DIR_A, COMBINED_TRAIN_DIR, 'fake')\n",
    "copy_images(TRAIN_DIR_A, COMBINED_TRAIN_DIR, 'real')\n",
    "\n",
    "# Copy images from Dataset B (assuming it has 'fake' and 'real' subdirs)\n",
    "print(\"Copying Dataset B images...\")\n",
    "copy_images(DATASET_B_PATH, COMBINED_TRAIN_DIR, 'fake')\n",
    "copy_images(DATASET_B_PATH, COMBINED_TRAIN_DIR, 'real')\n",
    "\n",
    "print(\"Finished preparing combined training data.\")\n",
    "\n",
    "# =====================================\n",
    "# 2. Create Data Generators\n",
    "# =====================================\n",
    "# Generator for combined training data (with augmentation if desired)\n",
    "train_datagen_combined = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # Add augmentations if you used them in the original training, e.g.:\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.02,\n",
    "    height_shift_range=0.02,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generator for Dataset A validation data (only rescaling)\n",
    "valid_test_datagen_A = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generator for Dataset B data (only rescaling) - for evaluation\n",
    "datagen_B = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Create the generator flows\n",
    "print(\"Creating data generators...\")\n",
    "train_generator_combined = train_datagen_combined.flow_from_directory(\n",
    "    COMBINED_TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Use the original validation generator for Dataset A\n",
    "valid_generator_A = valid_test_datagen_A.flow_from_directory(\n",
    "    VAL_DIR_A,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Use the original test generator for Dataset A\n",
    "test_generator_A = valid_test_datagen_A.flow_from_directory(\n",
    "    TEST_DIR_A,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create a generator for evaluating on all of Dataset B\n",
    "# We reuse the DATASET_B_PATH, assuming it directly contains 'fake'/'real' folders\n",
    "generator_B = datagen_B.flow_from_directory(\n",
    "    DATASET_B_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Verify class indices are consistent (should be {'fake': 0, 'real': 1})\n",
    "print(\"Class indices (Combined Train):\", train_generator_combined.class_indices)\n",
    "print(\"Class indices (Dataset A Val):\", valid_generator_A.class_indices)\n",
    "print(\"Class indices (Dataset B Eval):\", generator_B.class_indices)\n",
    "# If indices are different or swapped, this indicates a problem in data setup!\n",
    "\n",
    "# =====================================\n",
    "# 3. Load Pre-trained Model and Re-compile\n",
    "# =====================================\n",
    "print(f\"Loading pre-trained model from {PRETRAINED_MODEL_PATH}...\")\n",
    "try:\n",
    "    model = tf.keras.models.load_model(PRETRAINED_MODEL_PATH)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    # Optional: Print model summary to verify\n",
    "    # model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Re-compile the model with a low learning rate for fine-tuning\n",
    "# It's important to use a *new* optimizer instance\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE), # Use Adam optimizer with the specified low learning rate\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(f\"Model re-compiled with learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# =====================================\n",
    "# 4. Fine-tune the Model\n",
    "# =====================================\n",
    "# Setup EarlyStopping for fine-tuning\n",
    "early_stop_finetune = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor validation loss on Dataset A's validation set\n",
    "    patience=3,               # Stop if no improvement after 3 epochs (can adjust)\n",
    "    restore_best_weights=True # Restore weights from the epoch with the best validation loss\n",
    ")\n",
    "\n",
    "print(\"Starting fine-tuning...\")\n",
    "history_finetune = model.fit(\n",
    "    train_generator_combined,\n",
    "    steps_per_epoch=max(1, train_generator_combined.samples // BATCH_SIZE), # Ensure at least 1 step\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_generator_A,\n",
    "    validation_steps=max(1, valid_generator_A.samples // BATCH_SIZE), # Ensure at least 1 step\n",
    "    callbacks=[early_stop_finetune]\n",
    ")\n",
    "print(\"Fine-tuning finished.\")\n",
    "\n",
    "# =====================================\n",
    "# 5. Evaluate the Fine-tuned Model\n",
    "# =====================================\n",
    "print(\"\\nEvaluating fine-tuned model on Dataset A (Test Set)...\")\n",
    "eval_A = model.evaluate(test_generator_A)\n",
    "print(f\"Dataset A - Test Loss: {eval_A[0]:.4f}, Test Accuracy: {eval_A[1]:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating fine-tuned model on Dataset B...\")\n",
    "eval_B = model.evaluate(generator_B)\n",
    "print(f\"Dataset B - Loss: {eval_B[0]:.4f}, Accuracy: {eval_B[1]:.4f}\")\n",
    "\n",
    "# Detailed report for Dataset B\n",
    "print(\"\\nGenerating detailed report for Dataset B...\")\n",
    "try:\n",
    "    predictions_B = model.predict(generator_B)\n",
    "    predicted_classes_B = (predictions_B > 0.5).astype(int).flatten()\n",
    "    true_classes_B = generator_B.classes\n",
    "    target_names_B = [k for k, v in sorted(generator_B.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "    print(\"\\nDataset B - Accuracy Score:\", accuracy_score(true_classes_B, predicted_classes_B))\n",
    "    print(\"\\nDataset B - Classification Report:\")\n",
    "    print(classification_report(true_classes_B, predicted_classes_B, target_names=target_names_B))\n",
    "\n",
    "    print(\"\\nDataset B - Confusion Matrix:\")\n",
    "    cm_B = confusion_matrix(true_classes_B, predicted_classes_B)\n",
    "    print(cm_B)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_B, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_B, yticklabels=target_names_B)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix on Dataset B (Fine-tuned Model)')\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during detailed evaluation on Dataset B: {e}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 6. Save the Fine-tuned Model\n",
    "# =====================================\n",
    "print(f\"\\nSaving the fine-tuned model to {FINETUNED_MODEL_PATH}...\")\n",
    "try:\n",
    "    model.save(FINETUNED_MODEL_PATH)\n",
    "    print(\"Fine-tuned model saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving fine-tuned model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locating/Downloading Dataset B ('hardfakevsrealfaces')...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Dataset B path: C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\n",
      "\n",
      "Preparing combined test data in ./combined_test_data_for_evaluation...\n",
      "Copying Dataset A test images for combined set...\n",
      "Copied 10000 images from C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/test\\fake (as DatasetA) to ./combined_test_data_for_evaluation\\fake\n",
      "Copied 10000 images from C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/test\\real (as DatasetA) to ./combined_test_data_for_evaluation\\real\n",
      "Copying Dataset B images for combined set...\n",
      "Copied 700 images from C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\\fake (as DatasetB) to ./combined_test_data_for_evaluation\\fake\n",
      "Copied 589 images from C:\\Users\\lzx13\\.cache\\kagglehub\\datasets\\hamzaboulahia\\hardfakevsrealfaces\\versions\\1\\real (as DatasetB) to ./combined_test_data_for_evaluation\\real\n",
      "Finished preparing combined test data.\n",
      "\n",
      "Creating data generators for evaluation...\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 1289 images belonging to 2 classes.\n",
      "Found 21289 images belonging to 2 classes.\n",
      "\n",
      "Class Indices (should be consistent, e.g., {'fake': 0, 'real': 1}):\n",
      "  Dataset A Val: {'fake': 0, 'real': 1}\n",
      "  Dataset A Test: {'fake': 0, 'real': 1}\n",
      "  Dataset B: {'fake': 0, 'real': 1}\n",
      "  Combined Test: {'fake': 0, 'real': 1}\n",
      "\n",
      "--- Evaluating Model: Initial Model (A) ---\n",
      "Successfully loaded and compiled: ./my_model_trained_on_A.keras\n",
      "\n",
      "  Evaluating on Dataset A Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lzx13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loss: 0.0601, Accuracy: 0.9798\n",
      "\n",
      "  Evaluating on Dataset A Test Set...\n",
      "    Loss: 0.0626, Accuracy: 0.9782\n",
      "\n",
      "  Evaluating on Dataset B...\n",
      "    Loss: 1.6982, Accuracy: 0.6330\n",
      "\n",
      "  Evaluating on Combined Test Set...\n",
      "    Loss: 0.1616, Accuracy: 0.9573\n",
      "\n",
      "--- Evaluating Model: FineTuned Model V1 ---\n",
      "Successfully loaded and compiled: ./my_model_finetuned.keras\n",
      "\n",
      "  Evaluating on Dataset A Validation Set...\n",
      "    Loss: 0.0574, Accuracy: 0.9805\n",
      "\n",
      "  Evaluating on Dataset A Test Set...\n",
      "    Loss: 0.0624, Accuracy: 0.9789\n",
      "\n",
      "  Evaluating on Dataset B...\n",
      "    Loss: 0.2711, Accuracy: 0.9061\n",
      "\n",
      "  Evaluating on Combined Test Set...\n",
      "    Loss: 0.0751, Accuracy: 0.9745\n",
      "\n",
      "--- Evaluating Model: FineTuned Model V2 ---\n",
      "Successfully loaded and compiled: ./my_model_finetuned_v2.keras\n",
      "\n",
      "  Evaluating on Dataset A Validation Set...\n",
      "    Loss: 0.1293, Accuracy: 0.9522\n",
      "\n",
      "  Evaluating on Dataset A Test Set...\n",
      "    Loss: 0.1275, Accuracy: 0.9527\n",
      "\n",
      "  Evaluating on Dataset B...\n",
      "    Loss: 0.1978, Accuracy: 0.9178\n",
      "\n",
      "  Evaluating on Combined Test Set...\n",
      "    Loss: 0.1317, Accuracy: 0.9506\n",
      "\n",
      "--- Evaluating Model: FineTuned Model V3 ---\n",
      "Successfully loaded and compiled: ./my_model_finetuned_v3.keras\n",
      "\n",
      "  Evaluating on Dataset A Validation Set...\n",
      "    Loss: 0.1492, Accuracy: 0.9441\n",
      "\n",
      "  Evaluating on Dataset A Test Set...\n",
      "    Loss: 0.1471, Accuracy: 0.9435\n",
      "\n",
      "  Evaluating on Dataset B...\n",
      "    Loss: 0.2638, Accuracy: 0.8844\n",
      "\n",
      "  Evaluating on Combined Test Set...\n",
      "    Loss: 0.1541, Accuracy: 0.9400\n",
      "\n",
      "\n",
      "--- Overall Results Summary ---\n",
      "\n",
      "Model: Initial Model (A)\n",
      "  Dataset A Validation: Loss = 0.0601, Accuracy = 0.9798\n",
      "  Dataset A Test: Loss = 0.0626, Accuracy = 0.9782\n",
      "  Dataset B: Loss = 1.6982, Accuracy = 0.6330\n",
      "  Combined Test Set: Loss = 0.1616, Accuracy = 0.9573\n",
      "\n",
      "Model: FineTuned Model V1\n",
      "  Dataset A Validation: Loss = 0.0574, Accuracy = 0.9805\n",
      "  Dataset A Test: Loss = 0.0624, Accuracy = 0.9789\n",
      "  Dataset B: Loss = 0.2711, Accuracy = 0.9061\n",
      "  Combined Test Set: Loss = 0.0751, Accuracy = 0.9745\n",
      "\n",
      "Model: FineTuned Model V2\n",
      "  Dataset A Validation: Loss = 0.1293, Accuracy = 0.9522\n",
      "  Dataset A Test: Loss = 0.1275, Accuracy = 0.9527\n",
      "  Dataset B: Loss = 0.1978, Accuracy = 0.9178\n",
      "  Combined Test Set: Loss = 0.1317, Accuracy = 0.9506\n",
      "\n",
      "Model: FineTuned Model V3\n",
      "  Dataset A Validation: Loss = 0.1492, Accuracy = 0.9441\n",
      "  Dataset A Test: Loss = 0.1471, Accuracy = 0.9435\n",
      "  Dataset B: Loss = 0.2638, Accuracy = 0.8844\n",
      "  Combined Test Set: Loss = 0.1541, Accuracy = 0.9400\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam # Or any optimizer, just for compilation\n",
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "# =====================================\n",
    "# Configuration\n",
    "# =====================================\n",
    "# --- Define paths to your models ---\n",
    "MODEL_PATHS = {\n",
    "    \"Initial Model (A)\": \"./my_model_trained_on_A.keras\",\n",
    "    \"FineTuned Model V1\": \"./my_model_finetuned.keras\",\n",
    "    \"FineTuned Model V2\": \"./my_model_finetuned_v2.keras\",\n",
    "    \"FineTuned Model V3\": \"./my_model_finetuned_v3.keras\", # Add this if you ran V3\n",
    "}\n",
    "\n",
    "# --- Dataset Paths (Ensure these are correct) ---\n",
    "# Dataset A\n",
    "VAL_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/valid'\n",
    "TEST_DIR_A = 'C:/Users/lzx13/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2/real_vs_fake/real-vs-fake/test'\n",
    "\n",
    "# Dataset B\n",
    "print(\"Locating/Downloading Dataset B ('hardfakevsrealfaces')...\")\n",
    "try:\n",
    "    DATASET_B_PATH = kagglehub.dataset_download(\"hamzaboulahia/hardfakevsrealfaces\")\n",
    "    print(f\"Dataset B path: {DATASET_B_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading/locating dataset B with kagglehub: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Path for the new combined test data\n",
    "COMBINED_TEST_DIR = './combined_test_data_for_evaluation'\n",
    "\n",
    "# --- General Parameters ---\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32 # For evaluation, batch size doesn't impact results, only speed/memory\n",
    "\n",
    "# =====================================\n",
    "# Helper function to copy images\n",
    "# =====================================\n",
    "def copy_images_for_evaluation(src_dir_base, dest_dir_base, class_name, dataset_prefix):\n",
    "    \"\"\"Copies images from src_dir_base/class_name to dest_dir_base/class_name with a prefix.\"\"\"\n",
    "    src_class_dir = os.path.join(src_dir_base, class_name)\n",
    "    dest_class_dir = os.path.join(dest_dir_base, class_name)\n",
    "    \n",
    "    if not os.path.exists(src_class_dir):\n",
    "        print(f\"Warning: Source directory not found for copying: {src_class_dir}\")\n",
    "        return 0\n",
    "    \n",
    "    os.makedirs(dest_class_dir, exist_ok=True) # Ensure destination class directory exists\n",
    "    \n",
    "    count = 0\n",
    "    for filename in os.listdir(src_class_dir):\n",
    "        src_file = os.path.join(src_class_dir, filename)\n",
    "        if os.path.isfile(src_file):\n",
    "            try:\n",
    "                # Add a prefix to avoid name collisions between datasets\n",
    "                new_filename = f\"{dataset_prefix}_{class_name}_{filename}\"\n",
    "                dest_file_prefixed = os.path.join(dest_class_dir, new_filename)\n",
    "                shutil.copy2(src_file, dest_file_prefixed)\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file} to {dest_file_prefixed}: {e}\")\n",
    "    print(f\"Copied {count} images from {src_class_dir} (as {dataset_prefix}) to {dest_class_dir}\")\n",
    "    return count\n",
    "\n",
    "# =====================================\n",
    "# 1. Prepare Combined Test Data\n",
    "# =====================================\n",
    "print(f\"\\nPreparing combined test data in {COMBINED_TEST_DIR}...\")\n",
    "if os.path.exists(COMBINED_TEST_DIR):\n",
    "    print(f\"Removing existing combined test directory: {COMBINED_TEST_DIR}\")\n",
    "    shutil.rmtree(COMBINED_TEST_DIR)\n",
    "\n",
    "os.makedirs(os.path.join(COMBINED_TEST_DIR, 'fake'), exist_ok=True)\n",
    "os.makedirs(os.path.join(COMBINED_TEST_DIR, 'real'), exist_ok=True)\n",
    "\n",
    "# Copy test images from Dataset A\n",
    "print(\"Copying Dataset A test images for combined set...\")\n",
    "copy_images_for_evaluation(TEST_DIR_A, COMBINED_TEST_DIR, 'fake', 'DatasetA')\n",
    "copy_images_for_evaluation(TEST_DIR_A, COMBINED_TEST_DIR, 'real', 'DatasetA')\n",
    "\n",
    "# Copy all images from Dataset B (as its \"test\" set)\n",
    "print(\"Copying Dataset B images for combined set...\")\n",
    "# Ensure DATASET_B_PATH directly contains 'fake' and 'real' subdirs\n",
    "copy_images_for_evaluation(DATASET_B_PATH, COMBINED_TEST_DIR, 'fake', 'DatasetB')\n",
    "copy_images_for_evaluation(DATASET_B_PATH, COMBINED_TEST_DIR, 'real', 'DatasetB')\n",
    "\n",
    "print(\"Finished preparing combined test data.\")\n",
    "\n",
    "# =====================================\n",
    "# 2. Create Data Generators for Evaluation\n",
    "# =====================================\n",
    "print(\"\\nCreating data generators for evaluation...\")\n",
    "eval_datagen = ImageDataGenerator(rescale=1./255) # Only rescaling for evaluation\n",
    "\n",
    "# Generator for Dataset A Validation Set\n",
    "valid_generator_A = eval_datagen.flow_from_directory(\n",
    "    VAL_DIR_A,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False # IMPORTANT for evaluation\n",
    ")\n",
    "\n",
    "# Generator for Dataset A Test Set\n",
    "test_generator_A = eval_datagen.flow_from_directory(\n",
    "    TEST_DIR_A,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False # IMPORTANT\n",
    ")\n",
    "\n",
    "# Generator for Dataset B (all data)\n",
    "generator_B = eval_datagen.flow_from_directory(\n",
    "    DATASET_B_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False # IMPORTANT\n",
    ")\n",
    "\n",
    "# Generator for the Combined Test Set\n",
    "combined_test_generator = eval_datagen.flow_from_directory(\n",
    "    COMBINED_TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False # IMPORTANT\n",
    ")\n",
    "\n",
    "print(\"\\nClass Indices (should be consistent, e.g., {'fake': 0, 'real': 1}):\")\n",
    "print(f\"  Dataset A Val: {valid_generator_A.class_indices}\")\n",
    "print(f\"  Dataset A Test: {test_generator_A.class_indices}\")\n",
    "print(f\"  Dataset B: {generator_B.class_indices}\")\n",
    "print(f\"  Combined Test: {combined_test_generator.class_indices}\")\n",
    "\n",
    "# =====================================\n",
    "# 3. Evaluate Models\n",
    "# =====================================\n",
    "results_summary = {}\n",
    "\n",
    "for model_name, model_path in MODEL_PATHS.items():\n",
    "    print(f\"\\n--- Evaluating Model: {model_name} ---\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file not found: {model_path}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        # Compile is not strictly necessary for evaluate if model was saved compiled,\n",
    "        # but doing so ensures metrics are consistently defined.\n",
    "        model.compile(optimizer=Adam(learning_rate=1e-5), # LR doesn't matter for eval\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        print(f\"Successfully loaded and compiled: {model_path}\")\n",
    "\n",
    "        model_results = {}\n",
    "\n",
    "        # Evaluate on Dataset A Validation Set\n",
    "        print(f\"\\n  Evaluating on Dataset A Validation Set...\")\n",
    "        valid_A_results = model.evaluate(valid_generator_A, verbose=0)\n",
    "        model_results[\"Dataset A Validation\"] = {\"loss\": valid_A_results[0], \"accuracy\": valid_A_results[1]}\n",
    "        print(f\"    Loss: {valid_A_results[0]:.4f}, Accuracy: {valid_A_results[1]:.4f}\")\n",
    "        valid_generator_A.reset() # Good practice\n",
    "\n",
    "        # Evaluate on Dataset A Test Set\n",
    "        print(f\"\\n  Evaluating on Dataset A Test Set...\")\n",
    "        test_A_results = model.evaluate(test_generator_A, verbose=0)\n",
    "        model_results[\"Dataset A Test\"] = {\"loss\": test_A_results[0], \"accuracy\": test_A_results[1]}\n",
    "        print(f\"    Loss: {test_A_results[0]:.4f}, Accuracy: {test_A_results[1]:.4f}\")\n",
    "        test_generator_A.reset()\n",
    "\n",
    "        # Evaluate on Dataset B\n",
    "        print(f\"\\n  Evaluating on Dataset B...\")\n",
    "        test_B_results = model.evaluate(generator_B, verbose=0)\n",
    "        model_results[\"Dataset B\"] = {\"loss\": test_B_results[0], \"accuracy\": test_B_results[1]}\n",
    "        print(f\"    Loss: {test_B_results[0]:.4f}, Accuracy: {test_B_results[1]:.4f}\")\n",
    "        generator_B.reset()\n",
    "        \n",
    "        # Evaluate on Combined Test Set\n",
    "        print(f\"\\n  Evaluating on Combined Test Set...\")\n",
    "        combined_test_results = model.evaluate(combined_test_generator, verbose=0)\n",
    "        model_results[\"Combined Test Set\"] = {\"loss\": combined_test_results[0], \"accuracy\": combined_test_results[1]}\n",
    "        print(f\"    Loss: {combined_test_results[0]:.4f}, Accuracy: {combined_test_results[1]:.4f}\")\n",
    "        combined_test_generator.reset()\n",
    "\n",
    "        results_summary[model_name] = model_results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model {model_name} from {model_path}: {e}\")\n",
    "\n",
    "# =====================================\n",
    "# 4. Print Summary of Results\n",
    "# =====================================\n",
    "print(\"\\n\\n--- Overall Results Summary ---\")\n",
    "for model_name, evaluations in results_summary.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for eval_name, metrics in evaluations.items():\n",
    "        print(f\"  {eval_name}: Loss = {metrics['loss']:.4f}, Accuracy = {metrics['accuracy']:.4f}\")\n",
    "\n",
    "# =====================================\n",
    "# 5. Optional: Cleanup Combined Test Directory\n",
    "# =====================================\n",
    "# try:\n",
    "#     print(f\"\\nRemoving temporary combined test directory: {COMBINED_TEST_DIR}\")\n",
    "#     shutil.rmtree(COMBINED_TEST_DIR)\n",
    "#     print(\"Cleanup successful.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error during cleanup: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
